{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pycocotools.coco\n",
    "import pycocotools.cocoeval\n",
    "import os\n",
    "import torch\n",
    "import PIL.Image\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "import trt_pose.plugins\n",
    "import trt_pose.models\n",
    "import trt_pose.coco\n",
    "import tqdm\n",
    "import json\n",
    "from trt_pose.parse_objects import ParseObjects"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "NOTE! Installing ujson may make loading annotations faster.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "with open('models/human_pose.json', 'r') as f:\n",
    "    human_pose = json.load(f)\n",
    "\n",
    "topology = trt_pose.coco.coco_category_to_topology(human_pose)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "num_parts = len(human_pose['keypoints'])\n",
    "num_links = len(human_pose['skeleton'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "model = trt_pose.models.resnet50_baseline_att(num_parts, 2 * num_links)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model.load_state_dict(torch.load('experiments/resnet18_baseline_att_368x368_A.json.checkpoints/epoch_249.pth'))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "data = torch.zeros((1, 3, 368, 368)).cuda()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "model = model.cuda().eval()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "cmap, paf = model(torch.zeros((1, 3, 368, 368)).cuda())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1153.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "cmap.shape\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 18, 64, 64])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "paf.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 42, 64, 64])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "IMAGE_SHAPE = (368, 368)\n",
    "images_dir = '../../trt_pose/val2017'\n",
    "annotation_file = 'annotations/person_keypoints_val2017_modified.json'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "cocoGtTmp = pycocotools.coco.COCO('../../trt_pose/annotations/person_keypoints_val2017_modified.json')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.28s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "topology = trt_pose.coco.coco_category_to_topology(cocoGtTmp.cats[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "cocoGt = pycocotools.coco.COCO('../../trt_pose/annotations/person_keypoints_val2017.json')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.31s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "catIds = cocoGt.getCatIds('person')\n",
    "imgIds = cocoGt.getImgIds(catIds=catIds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "parse_objects = ParseObjects(topology, cmap_threshold=0.05, link_threshold=0.1, cmap_window=11, line_integral_samples=7, max_num_parts=100, max_num_objects=100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "results = []\n",
    "\n",
    "for n, imgId in enumerate(imgIds):\n",
    "    \n",
    "    # read image\n",
    "    img = cocoGt.imgs[imgId]\n",
    "    img_path = os.path.join(images_dir, img['file_name'])\n",
    "\n",
    "    image = PIL.Image.open(img_path).convert('RGB').resize(IMAGE_SHAPE)\n",
    "    data = transform(image).cuda()[None, ...]\n",
    "\n",
    "    cmap, paf = model(data)\n",
    "    cmap, paf = cmap.cpu(), paf.cpu()\n",
    "\n",
    "#     object_counts, objects, peaks, int_peaks = postprocess(cmap, paf, cmap_threshold=0.05, link_threshold=0.01, window=5)\n",
    "#     object_counts, objects, peaks = int(object_counts[0]), objects[0], peaks[0]\n",
    "    \n",
    "    object_counts, objects, peaks = parse_objects(cmap, paf)\n",
    "    object_counts, objects, peaks = int(object_counts[0]), objects[0], peaks[0]\n",
    "\n",
    "    for i in range(object_counts):\n",
    "        object = objects[i]\n",
    "        score = 0.0\n",
    "        kps = [0]*(17*3)\n",
    "        x_mean = 0\n",
    "        y_mean = 0\n",
    "        cnt = 0\n",
    "        for j in range(17):\n",
    "            k = object[j]\n",
    "            if k >= 0:\n",
    "                peak = peaks[j][k]\n",
    "                x = round(float(img['width'] * peak[1]))\n",
    "                y = round(float(img['height'] * peak[0]))\n",
    "                score += 1.0\n",
    "                kps[j * 3 + 0] = x\n",
    "                kps[j * 3 + 1] = y\n",
    "                kps[j * 3 + 2] = 2\n",
    "                x_mean += x\n",
    "                y_mean += y\n",
    "                cnt += 1\n",
    "\n",
    "        ann = {\n",
    "            'image_id': imgId,\n",
    "            'category_id': 1,\n",
    "            'keypoints': kps,\n",
    "            'score': score / 17.0\n",
    "        }\n",
    "        results.append(ann)\n",
    "    if n % 100 == 0:\n",
    "        print('%d / %d' % (n, len(imgIds)))\n",
    "#     break\n",
    "        \n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 / 2693\n",
      "100 / 2693\n",
      "200 / 2693\n",
      "300 / 2693\n",
      "400 / 2693\n",
      "500 / 2693\n",
      "600 / 2693\n",
      "700 / 2693\n",
      "800 / 2693\n",
      "900 / 2693\n",
      "1000 / 2693\n",
      "1100 / 2693\n",
      "1200 / 2693\n",
      "1300 / 2693\n",
      "1400 / 2693\n",
      "1500 / 2693\n",
      "1600 / 2693\n",
      "1700 / 2693\n",
      "1800 / 2693\n",
      "1900 / 2693\n",
      "2000 / 2693\n",
      "2100 / 2693\n",
      "2200 / 2693\n",
      "2300 / 2693\n",
      "2400 / 2693\n",
      "2500 / 2693\n",
      "2600 / 2693\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "cocoDt = cocoGt.loadRes('results.json')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.39s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "cocoEval = pycocotools.cocoeval.COCOeval(cocoGt, cocoDt, 'keypoints')\n",
    "cocoEval.params.imgIds = imgIds\n",
    "cocoEval.params.catIds = [1]\n",
    "cocoEval.evaluate()\n",
    "cocoEval.accumulate()\n",
    "cocoEval.summarize()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running per image evaluation...\n",
      "Evaluate annotation type *keypoints*\n",
      "DONE (t=4.52s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.09s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.24617\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.45277\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.23746\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = 0.12129\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.42217\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 20 ] = 0.32032\n",
      " Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets= 20 ] = 0.49795\n",
      " Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets= 20 ] = 0.32950\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets= 20 ] = 0.13201\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets= 20 ] = 0.57800\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}